{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1bed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1497 promoters and 11459 non-promoters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25db35cdf1e74637b8619b3ef1557540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2395 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7427d6c12fce473698dc64914be7c204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dd2be5d18f4b9582d7f646fe80e410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to Arabidopsis_promoter_dataset_tata\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info'],\n",
      "        num_rows: 2395\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info'],\n",
      "        num_rows: 299\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info'],\n",
      "        num_rows: 300\n",
      "    })\n",
      "})\n",
      "Train: 2395 examples\n",
      "Validation: 299 examples\n",
      "Test: 300 examples\n",
      "\n",
      "Class balance in training set:\n",
      "Promoters: 1205 (50.3%)\n",
      "Non-promoters: 1190 (49.7%)\n",
      "\n",
      "Sample from training set:\n",
      "Example 1 (Non-Promoter):\n",
      "Sequence: TCAGTCCGGTGCTCTTCGAGTCTCACATGTATCAACACGAGATCAACTAG... (251 bp)\n",
      "Gene ID: \n",
      "Description: retrotransposon like protein, AT4g16870, similarity to copia-like retrotransp\n",
      "Range Info: None\n",
      "Label: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2 (Promoter):\n",
      "Sequence: AAATGCATGACGTTATGGAATGAAATGACGAAGTTACCCTTAAATGCAAC... (251 bp)\n",
      "Gene ID: AT1G21070_1\n",
      "Description: None\n",
      "Range Info: :+U EU:NC; range -200 to 50.\n",
      "Label: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3 (Promoter):\n",
      "Sequence: CGTCGTCGACAAGACAAGGCTAAGCTATCGAAAATTAAATGTACAATATC... (251 bp)\n",
      "Gene ID: AT3G03640_1\n",
      "Description: None\n",
      "Range Info: :+U EU:NC; range -200 to 50.\n",
      "Label: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code to create a HuggingFace dataset from promoter and non-promoter FASTA files\n",
    "import os\n",
    "import random\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def parse_non_promoter_fasta(file_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse non-promoter FASTA file with format:\n",
    "    >DNA excision repair cross-complementing protein, gene_id:MYC6.7 [AB006707 AB020748 AB005233]\n",
    "    GTTCATTTAGAATGTGTATCCACTATCCAGTGTTACTGGGATCTACAAATAACAAGTTTCC...\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    current_header = \"\"\n",
    "    current_seq = \"\"\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                # Save the previous sequence if it exists\n",
    "                if current_header and current_seq:\n",
    "                    # Extract gene ID if possible\n",
    "                    gene_id = \"\"\n",
    "                    if \"gene_id:\" in current_header:\n",
    "                        try:\n",
    "                            gene_id = current_header.split(\"gene_id:\")[1].split()[0].strip()\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    # Extract description\n",
    "                    description = current_header\n",
    "                    if \"[\" in description:\n",
    "                        description = description.split(\"[\")[0].strip()\n",
    "                    \n",
    "                    sequences.append({\n",
    "                        'seq': current_seq,\n",
    "                        'description': description,\n",
    "                        'gene_id': gene_id,\n",
    "                        'is_promoter': 0,  # 0 for non-promoter\n",
    "                        'label': 0         # Label for classification\n",
    "                    })\n",
    "                \n",
    "                # Start new sequence\n",
    "                current_header = line[1:]  # Remove '>' character\n",
    "                current_seq = \"\"\n",
    "            else:\n",
    "                current_seq += line\n",
    "        \n",
    "        # Add the last sequence\n",
    "        if current_header and current_seq:\n",
    "            gene_id = \"\"\n",
    "            if \"gene_id:\" in current_header:\n",
    "                try:\n",
    "                    gene_id = current_header.split(\"gene_id:\")[1].split()[0].strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            description = current_header\n",
    "            if \"[\" in description:\n",
    "                description = description.split(\"[\")[0].strip()\n",
    "            \n",
    "            sequences.append({\n",
    "                'seq': current_seq,\n",
    "                'description': description,\n",
    "                'gene_id': gene_id,\n",
    "                'is_promoter': 0,\n",
    "                'label': 0\n",
    "            })\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def parse_promoter_fasta(file_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse promoter FASTA file with format:\n",
    "    >FP000001 AT1G01050_1 :+U EU:NC; range -200 to 50.\n",
    "    CAAGTATCCTACATAGATTATAGGAGTGACCGCAAAAACACAAACTATGTTTCGTAATAA...\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    current_header = \"\"\n",
    "    current_seq = \"\"\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                # Save the previous sequence if it exists\n",
    "                if current_header and current_seq:\n",
    "                    parts = current_header.split()\n",
    "                    fp_id = parts[0] if len(parts) > 0 else \"\"\n",
    "                    gene_id = parts[1] if len(parts) > 1 else \"\"\n",
    "                    range_info = ' '.join(parts[2:]) if len(parts) > 2 else \"\"\n",
    "                    \n",
    "                    sequences.append({\n",
    "                        'seq': current_seq,\n",
    "                        'fp_id': fp_id,\n",
    "                        'gene_id': gene_id,\n",
    "                        'range_info': range_info,\n",
    "                        'is_promoter': 1,  # 1 for promoter\n",
    "                        'label': 1         # Label for classification\n",
    "                    })\n",
    "                \n",
    "                # Start new sequence\n",
    "                current_header = line[1:]\n",
    "                current_seq = \"\"\n",
    "            else:\n",
    "                current_seq += line\n",
    "        \n",
    "        # Add the last sequence\n",
    "        if current_header and current_seq:\n",
    "            parts = current_header.split()\n",
    "            fp_id = parts[0] if len(parts) > 0 else \"\"\n",
    "            gene_id = parts[1] if len(parts) > 1 else \"\"\n",
    "            range_info = ' '.join(parts[2:]) if len(parts) > 2 else \"\"\n",
    "            \n",
    "            sequences.append({\n",
    "                'seq': current_seq,\n",
    "                'fp_id': fp_id, \n",
    "                'gene_id': gene_id,\n",
    "                'range_info': range_info,\n",
    "                'is_promoter': 1,\n",
    "                'label': 1\n",
    "            })\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def create_dna_promoter_dataset(promoter_file: str, non_promoter_file: str, \n",
    "                               output_dir=None, train_split=0.8,\n",
    "                               val_split=0.1, test_split=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    Create a balanced HuggingFace dataset from promoter and non-promoter files.\n",
    "    \n",
    "    Args:\n",
    "        promoter_file: Path to the promoter FASTA file\n",
    "        non_promoter_file: Path to the non-promoter FASTA file\n",
    "        output_dir: Directory to save the dataset (optional)\n",
    "        train_split, val_split, test_split: Dataset split proportions\n",
    "        seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Check that files exist\n",
    "    if not os.path.exists(promoter_file):\n",
    "        raise FileNotFoundError(f\"Promoter file not found: {promoter_file}\")\n",
    "    if not os.path.exists(non_promoter_file):\n",
    "        raise FileNotFoundError(f\"Non-promoter file not found: {non_promoter_file}\")\n",
    "    \n",
    "    # Parse files\n",
    "    promoters = parse_promoter_fasta(promoter_file)\n",
    "    non_promoters = parse_non_promoter_fasta(non_promoter_file)\n",
    "    \n",
    "    print(f\"Found {len(promoters)} promoters and {len(non_promoters)} non-promoters\")\n",
    "    \n",
    "    # Balance the dataset\n",
    "    min_size = min(len(promoters), len(non_promoters))\n",
    "    \n",
    "    # Randomly sample to get balanced dataset\n",
    "    random.seed(seed)\n",
    "    sampled_promoters = random.sample(promoters, min_size)\n",
    "    sampled_non_promoters = random.sample(non_promoters, min_size)\n",
    "    \n",
    "    # Combine data\n",
    "    all_data = sampled_promoters + sampled_non_promoters\n",
    "    random.shuffle(all_data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Split into train/val/test\n",
    "    train_size = int(len(df) * train_split)\n",
    "    val_size = int(len(df) * val_split)\n",
    "    \n",
    "    train_df = df[:train_size]\n",
    "    val_df = df[train_size:train_size+val_size]\n",
    "    test_df = df[train_size+val_size:]\n",
    "    \n",
    "    # Create HuggingFace dataset\n",
    "    dataset_dict = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train_df),\n",
    "        'validation': Dataset.from_pandas(val_df),\n",
    "        'test': Dataset.from_pandas(test_df)\n",
    "    })\n",
    "    \n",
    "    # Save dataset if output directory is provided\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        dataset_dict.save_to_disk(output_dir)\n",
    "        print(f\"Dataset saved to {output_dir}\")\n",
    "    \n",
    "    return dataset_dict\n",
    "\n",
    "# Example usage - replace these with your actual file paths\n",
    "promoter_file = \"/home/foresti/mdlm/CNNPromoterData/Arabidopsis_tata.fa\"\n",
    "non_promoter_file = \"/home/foresti/mdlm/CNNPromoterData/Arabidopsis_non_prom_big.fa\"\n",
    "\n",
    "# Create and analyze the dataset\n",
    "dataset = create_dna_promoter_dataset(\n",
    "    promoter_file=promoter_file,\n",
    "    non_promoter_file=non_promoter_file,\n",
    "    output_dir=\"Arabidopsis_promoter_dataset_tata\"\n",
    ")\n",
    "\n",
    "# Print dataset info\n",
    "print(dataset)\n",
    "print(f\"Train: {len(dataset['train'])} examples\")\n",
    "print(f\"Validation: {len(dataset['validation'])} examples\")\n",
    "print(f\"Test: {len(dataset['test'])} examples\")\n",
    "\n",
    "# Check class balance\n",
    "train_promoters = sum(dataset['train']['is_promoter'])\n",
    "train_non_promoters = len(dataset['train']) - train_promoters\n",
    "print(f\"\\nClass balance in training set:\")\n",
    "print(f\"Promoters: {train_promoters} ({train_promoters/len(dataset['train'])*100:.1f}%)\")\n",
    "print(f\"Non-promoters: {train_non_promoters} ({train_non_promoters/len(dataset['train'])*100:.1f}%)\")\n",
    "\n",
    "# Display a few examples\n",
    "print(\"\\nSample from training set:\")\n",
    "for i in range(min(3, len(dataset['train']))):\n",
    "    example = dataset['train'][i]\n",
    "    label = \"Promoter\" if example['is_promoter'] == 1 else \"Non-Promoter\"\n",
    "    print(f\"Example {i+1} ({label}):\")\n",
    "    print(f\"Sequence: {example['seq'][:50]}... ({len(example['seq'])} bp)\")\n",
    "    print(f\"Gene ID: {example.get('gene_id', 'N/A')}\")\n",
    "    print(f\"Description: {example.get('description', 'N/A')}\")\n",
    "    print(f\"Range Info: {example.get('range_info', 'N/A')}\")\n",
    "    print(f\"Label: {example['label']}\")\n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
