{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foresti/miniconda3/envs/mdlm/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for alexfabbri/multi_news contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/alexfabbri/multi_news\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874317839f04467781d3fd8e5235afed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2444e042489443a92334343618e8830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/58.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4713a5f24e34628be47b2cf731f177f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/66.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ad34d4f04c4e17942d78d82f22de94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b5a3471dbf47cf8284fe188bf1aa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/69.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1a5ce321f44d59afb763a2f19e9785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7456386fc54e56bcc7765eac4c19b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa83d07d71b84dd99c00791affb1b1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bffdd20151b44408a266191861f93ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "!export HF_HOME=\"/home/foresti/.cache/huggingface\"\n",
    "!export HF_DATASET_CACHE=\"/home/foresti/.cache/huggingface/datasets\"\n",
    "db = datasets.load_dataset(\"alexfabbri/multi_news\", \"multi_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[CLS]': 0, '[SEP]': 1, '[BOS]': 2, '[MASK]': 3, '[PAD]': 4, '[RESERVED]': 5, '[UNK]': 6, 'A': 7, 'C': 8, 'G': 9, 'T': 10, 'N': 11}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "      \"kuleshov-group/caduceus-ph_seqlen-1k_d_model-256_n_layer-4_lr-8e-3\", trust_remote_code=True)\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Print the first few entries (vocab can be large)\n",
    "import itertools\n",
    "print(dict(itertools.islice(vocab.items(), 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['document', 'summary'],\n",
      "        num_rows: 44972\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['document', 'summary'],\n",
      "        num_rows: 5622\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['document', 'summary'],\n",
      "        num_rows: 5622\n",
      "    })\n",
      "})\n",
      "{'document': 'National Archives \\n \\n Yes, it’s that time again, folks. It’s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs. \\n \\n A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. New York time offering one of the most important snapshots on how the economy fared during the previous month. Expectations are for 203,000 new jobs to be created, according to economists polled by Dow Jones Newswires, compared to 227,000 jobs added in February. The unemployment rate is expected to hold steady at 8.3%. \\n \\n Here at MarketBeat HQ, we’ll be offering color commentary before and after the data crosses the wires. Feel free to weigh-in yourself, via the comments section. And while you’re here, why don’t you sign up to follow us on Twitter. \\n \\n Enjoy the show. ||||| Employers pulled back sharply on hiring last month, a reminder that the U.S. economy may not be growing fast enough to sustain robust job growth. The unemployment rate dipped, but mostly because more Americans stopped looking for work. \\n \\n The Labor Department says the economy added 120,000 jobs in March, down from more than 200,000 in each of the previous three months. \\n \\n The unemployment rate fell to 8.2 percent, the lowest since January 2009. The rate dropped because fewer people searched for jobs. The official unemployment tally only includes those seeking work. \\n \\n The economy has added 858,000 jobs since December _ the best four months of hiring in two years. But Federal Reserve Chairman Ben Bernanke has cautioned that the current hiring pace is unlikely to continue without more consumer spending.', 'summary': '– The unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to today\\'s jobs report. Reaction on the Wall Street Journal\\'s MarketBeat Blog was swift: \"Woah!!! Bad number.\" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.'}\n",
      "dict_keys(['document', 'summary'])\n",
      "National Archives \n",
      " \n",
      " Yes, it’s that time again, folks. It’s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs. \n",
      " \n",
      " A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. New York time offering one of the most important snapshots on how the economy fared during the previous month. Expectations are for 203,000 new jobs to be created, according to economists polled by Dow Jones Newswires, compared to 227,000 jobs added in February. The unemployment rate is expected to hold steady at 8.3%. \n",
      " \n",
      " Here at MarketBeat HQ, we’ll be offering color commentary before and after the data crosses the wires. Feel free to weigh-in yourself, via the comments section. And while you’re here, why don’t you sign up to follow us on Twitter. \n",
      " \n",
      " Enjoy the show. ||||| Employers pulled back sharply on hiring last month, a reminder that the U.S. economy may not be growing fast enough to sustain robust job growth. The unemployment rate dipped, but mostly because more Americans stopped looking for work. \n",
      " \n",
      " The Labor Department says the economy added 120,000 jobs in March, down from more than 200,000 in each of the previous three months. \n",
      " \n",
      " The unemployment rate fell to 8.2 percent, the lowest since January 2009. The rate dropped because fewer people searched for jobs. The official unemployment tally only includes those seeking work. \n",
      " \n",
      " The economy has added 858,000 jobs since December _ the best four months of hiring in two years. But Federal Reserve Chairman Ben Bernanke has cautioned that the current hiring pace is unlikely to continue without more consumer spending.\n",
      "– The unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to today's jobs report. Reaction on the Wall Street Journal's MarketBeat Blog was swift: \"Woah!!! Bad number.\" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.\n"
     ]
    }
   ],
   "source": [
    "# See dataset structure\n",
    "print(db)\n",
    "print(db['train'][0])\n",
    "print(db['train'][0].keys())\n",
    "print(db['train'][0]['document'])\n",
    "print(db['train'][0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foresti/miniconda3/envs/mdlm/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# See the `MDLM` collection page on the hub for list of available models.\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model_name = 'kuleshov-group/mdlm-owt'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info'],\n",
      "        num_rows: 9448\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info'],\n",
      "        num_rows: 1181\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info'],\n",
      "        num_rows: 1181\n",
      "    })\n",
      "})\n",
      "Column names: ['seq', 'description', 'gene_id', 'is_promoter', 'label', 'fp_id', 'range_info']\n",
      "\n",
      "Examples with at least one None value: 9448\n",
      "\n",
      "Null values by column:\n",
      "- description: 4718 null values (49.94%)\n",
      "- fp_id: 4730 null values (50.06%)\n",
      "- range_info: 4730 null values (50.06%)\n",
      "\n",
      "Examples with null values:\n",
      "\n",
      "Example 0:\n",
      "  seq: TTTGATAATATTTTTCTAATGGATACTTGTGTGATTTTGCTTTGCTGGCA...\n",
      "  description: putative receptor-like protein kinase, F18A8.10\n",
      "  gene_id: \n",
      "  is_promoter: 0\n",
      "  label: 0\n",
      "  fp_id: None\n",
      "  range_info: None\n",
      "\n",
      "Example 1:\n",
      "  seq: TTAAAGAGAACCATAAGAAAACTAGTTTACGACATTATTATTTTCCGATT...\n",
      "  description: None\n",
      "  gene_id: AT1G14450_1\n",
      "  is_promoter: 1\n",
      "  label: 1\n",
      "  fp_id: FP000351\n",
      "  range_info: :+U EU:NC; range -200 to 50.\n",
      "\n",
      "Example 2:\n",
      "  seq: TTAACACGCGTTCAATAAAATTGGAATGATGCAAGTGTGGACCATAAAAG...\n",
      "  description: None\n",
      "  gene_id: AT5G04710_1\n",
      "  is_promoter: 1\n",
      "  label: 1\n",
      "  fp_id: FP004598\n",
      "  range_info: :+U EU:NC; range -200 to 50.\n",
      "\n",
      "Code to filter out problematic examples:\n",
      "\n",
      "# Filter out examples with None values\n",
      "def filter_none_values(example):\n",
      "    return not any(value is None for value in example.values())\n",
      "\n",
      "# Create filtered dataset\n",
      "filtered_ds = ds.filter(filter_none_values)\n",
      "\n",
      "print(f\"Original dataset size: {len(ds['train'])}\")\n",
      "print(f\"Filtered dataset size: {len(filtered_ds['train'])}\")\n",
      "print(f\"Removed {len(ds['train']) - len(filtered_ds['train'])} examples with null values\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_from_disk(\"/home/foresti/mdlm/Genomic_Arabidopsis_promoter_dataset_non_tata\")\n",
    "\n",
    "# Print ds information\n",
    "print(ds)\n",
    "\n",
    "# Look for None values\n",
    "# Code to analyze dataset and find null values\n",
    "\n",
    "# 1. Check column names first\n",
    "print(\"Column names:\", ds[\"train\"].column_names)\n",
    "\n",
    "# 2. Check for completely None examples\n",
    "def check_none_example(example):\n",
    "    return any(value is None for value in example.values())\n",
    "\n",
    "# Count examples with at least one None value\n",
    "none_examples_count = sum(check_none_example(example) for example in ds[\"train\"])\n",
    "print(f\"\\nExamples with at least one None value: {none_examples_count}\")\n",
    "\n",
    "# 3. Check for None values in each column\n",
    "none_values_by_column = {}\n",
    "for column in ds[\"train\"].column_names:\n",
    "    none_count = sum(1 for example in ds[\"train\"] if example[column] is None)\n",
    "    if none_count > 0:\n",
    "        none_values_by_column[column] = none_count\n",
    "\n",
    "print(\"\\nNull values by column:\")\n",
    "for column, count in none_values_by_column.items():\n",
    "    print(f\"- {column}: {count} null values ({count/len(ds['train'])*100:.2f}%)\")\n",
    "\n",
    "# 4. Show examples of records with null values (up to 3)\n",
    "print(\"\\nExamples with null values:\")\n",
    "count = 0\n",
    "for i, example in enumerate(ds[\"train\"]):\n",
    "    if check_none_example(example):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        for key, value in example.items():\n",
    "            print(f\"  {key}: {'None' if value is None else (value[:50]+'...' if isinstance(value, str) and len(value) > 50 else value)}\")\n",
    "        count += 1\n",
    "        if count >= 3:\n",
    "            break\n",
    "\n",
    "# 5. Code to filter out rows with None values\n",
    "print(\"\\nCode to filter out problematic examples:\")\n",
    "print(\"\"\"\n",
    "# Filter out examples with None values\n",
    "def filter_none_values(example):\n",
    "    return not any(value is None for value in example.values())\n",
    "\n",
    "# Create filtered dataset\n",
    "filtered_ds = ds.filter(filter_none_values)\n",
    "\n",
    "print(f\"Original dataset size: {len(ds['train'])}\")\n",
    "print(f\"Filtered dataset size: {len(filtered_ds['train'])}\")\n",
    "print(f\"Removed {len(ds['train']) - len(filtered_ds['train'])} examples with null values\")\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
